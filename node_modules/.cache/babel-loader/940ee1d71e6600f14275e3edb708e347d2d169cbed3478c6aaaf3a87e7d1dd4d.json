{"ast":null,"code":"import { __awaiter, __generator, __rest } from \"tslib\";\nimport { fetch } from '../../lib/fetch';\nimport { onPageChange } from '../../lib/on-page-change';\nvar MAX_PAYLOAD_SIZE = 500;\nfunction kilobytes(buffer) {\n  var size = encodeURI(JSON.stringify(buffer)).split(/%..|./).length - 1;\n  return size / 1024;\n}\n/**\n * Checks if the payload is over or close to\n * the maximum payload size allowed by tracking\n * API.\n */\nfunction approachingTrackingAPILimit(buffer) {\n  return kilobytes(buffer) >= MAX_PAYLOAD_SIZE - 50;\n}\nfunction chunks(batch) {\n  var result = [];\n  var index = 0;\n  batch.forEach(function (item) {\n    var size = kilobytes(result[index]);\n    if (size >= 64) {\n      index++;\n    }\n    if (result[index]) {\n      result[index].push(item);\n    } else {\n      result[index] = [item];\n    }\n  });\n  return result;\n}\nexport default function batch(apiHost, config) {\n  var _a, _b;\n  var buffer = [];\n  var pageUnloaded = false;\n  var limit = (_a = config === null || config === void 0 ? void 0 : config.size) !== null && _a !== void 0 ? _a : 10;\n  var timeout = (_b = config === null || config === void 0 ? void 0 : config.timeout) !== null && _b !== void 0 ? _b : 5000;\n  function sendBatch(batch) {\n    var _a;\n    if (batch.length === 0) {\n      return;\n    }\n    var writeKey = (_a = batch[0]) === null || _a === void 0 ? void 0 : _a.writeKey;\n    // Remove sentAt from every event as batching only needs a single timestamp\n    var updatedBatch = batch.map(function (event) {\n      var _a = event,\n        sentAt = _a.sentAt,\n        newEvent = __rest(_a, [\"sentAt\"]);\n      return newEvent;\n    });\n    return fetch(\"https://\".concat(apiHost, \"/b\"), {\n      keepalive: pageUnloaded,\n      headers: {\n        'Content-Type': 'text/plain'\n      },\n      method: 'post',\n      body: JSON.stringify({\n        writeKey: writeKey,\n        batch: updatedBatch,\n        sentAt: new Date().toISOString()\n      })\n    });\n  }\n  function flush() {\n    return __awaiter(this, void 0, void 0, function () {\n      var batch_1;\n      return __generator(this, function (_a) {\n        if (buffer.length) {\n          batch_1 = buffer;\n          buffer = [];\n          return [2 /*return*/, sendBatch(batch_1)];\n        }\n        return [2 /*return*/];\n      });\n    });\n  }\n  var schedule;\n  function scheduleFlush() {\n    if (schedule) {\n      return;\n    }\n    schedule = setTimeout(function () {\n      schedule = undefined;\n      flush().catch(console.error);\n    }, timeout);\n  }\n  onPageChange(function (unloaded) {\n    pageUnloaded = unloaded;\n    if (pageUnloaded && buffer.length) {\n      var reqs = chunks(buffer).map(sendBatch);\n      Promise.all(reqs).catch(console.error);\n    }\n  });\n  function dispatch(_url, body) {\n    return __awaiter(this, void 0, void 0, function () {\n      var bufferOverflow;\n      return __generator(this, function (_a) {\n        buffer.push(body);\n        bufferOverflow = buffer.length >= limit || approachingTrackingAPILimit(buffer);\n        return [2 /*return*/, bufferOverflow || pageUnloaded ? flush() : scheduleFlush()];\n      });\n    });\n  }\n  return {\n    dispatch: dispatch\n  };\n}","map":{"version":3,"names":["fetch","onPageChange","MAX_PAYLOAD_SIZE","kilobytes","buffer","size","encodeURI","JSON","stringify","split","length","approachingTrackingAPILimit","chunks","batch","result","index","forEach","item","push","apiHost","config","pageUnloaded","limit","_a","timeout","_b","sendBatch","writeKey","updatedBatch","map","event","sentAt","newEvent","__rest","concat","keepalive","headers","method","body","Date","toISOString","flush","batch_1","schedule","scheduleFlush","setTimeout","undefined","catch","console","error","unloaded","reqs","Promise","all","dispatch","_url","bufferOverflow"],"sources":["/Users/bcaudillo/Desktop/Projects/todo/node_modules/@segment/analytics-next/src/plugins/segmentio/batched-dispatcher.ts"],"sourcesContent":["import { SegmentEvent } from '../../core/events'\nimport { fetch } from '../../lib/fetch'\nimport { onPageChange } from '../../lib/on-page-change'\n\nexport type BatchingDispatchConfig = {\n  size?: number\n  timeout?: number\n}\n\nconst MAX_PAYLOAD_SIZE = 500\n\nfunction kilobytes(buffer: unknown): number {\n  const size = encodeURI(JSON.stringify(buffer)).split(/%..|./).length - 1\n  return size / 1024\n}\n\n/**\n * Checks if the payload is over or close to\n * the maximum payload size allowed by tracking\n * API.\n */\nfunction approachingTrackingAPILimit(buffer: unknown): boolean {\n  return kilobytes(buffer) >= MAX_PAYLOAD_SIZE - 50\n}\n\nfunction chunks(batch: object[]): Array<object[]> {\n  const result: object[][] = []\n  let index = 0\n\n  batch.forEach((item) => {\n    const size = kilobytes(result[index])\n    if (size >= 64) {\n      index++\n    }\n\n    if (result[index]) {\n      result[index].push(item)\n    } else {\n      result[index] = [item]\n    }\n  })\n\n  return result\n}\n\nexport default function batch(\n  apiHost: string,\n  config?: BatchingDispatchConfig\n) {\n  let buffer: object[] = []\n  let pageUnloaded = false\n\n  const limit = config?.size ?? 10\n  const timeout = config?.timeout ?? 5000\n\n  function sendBatch(batch: object[]) {\n    if (batch.length === 0) {\n      return\n    }\n\n    const writeKey = (batch[0] as SegmentEvent)?.writeKey\n\n    // Remove sentAt from every event as batching only needs a single timestamp\n    const updatedBatch = batch.map((event) => {\n      const { sentAt, ...newEvent } = event as SegmentEvent\n      return newEvent\n    })\n\n    return fetch(`https://${apiHost}/b`, {\n      keepalive: pageUnloaded,\n      headers: {\n        'Content-Type': 'text/plain',\n      },\n      method: 'post',\n      body: JSON.stringify({\n        writeKey,\n        batch: updatedBatch,\n        sentAt: new Date().toISOString(),\n      }),\n    })\n  }\n\n  async function flush(): Promise<unknown> {\n    if (buffer.length) {\n      const batch = buffer\n      buffer = []\n      return sendBatch(batch)\n    }\n  }\n\n  let schedule: NodeJS.Timeout | undefined\n\n  function scheduleFlush(): void {\n    if (schedule) {\n      return\n    }\n\n    schedule = setTimeout(() => {\n      schedule = undefined\n      flush().catch(console.error)\n    }, timeout)\n  }\n\n  onPageChange((unloaded) => {\n    pageUnloaded = unloaded\n\n    if (pageUnloaded && buffer.length) {\n      const reqs = chunks(buffer).map(sendBatch)\n      Promise.all(reqs).catch(console.error)\n    }\n  })\n\n  async function dispatch(_url: string, body: object): Promise<unknown> {\n    buffer.push(body)\n\n    const bufferOverflow =\n      buffer.length >= limit || approachingTrackingAPILimit(buffer)\n\n    return bufferOverflow || pageUnloaded ? flush() : scheduleFlush()\n  }\n\n  return {\n    dispatch,\n  }\n}\n"],"mappings":";AACA,SAASA,KAAK,QAAQ,iBAAiB;AACvC,SAASC,YAAY,QAAQ,0BAA0B;AAOvD,IAAMC,gBAAgB,GAAG,GAAG;AAE5B,SAASC,SAASA,CAACC,MAAe;EAChC,IAAMC,IAAI,GAAGC,SAAS,CAACC,IAAI,CAACC,SAAS,CAACJ,MAAM,CAAC,CAAC,CAACK,KAAK,CAAC,OAAO,CAAC,CAACC,MAAM,GAAG,CAAC;EACxE,OAAOL,IAAI,GAAG,IAAI;AACpB;AAEA;;;;;AAKA,SAASM,2BAA2BA,CAACP,MAAe;EAClD,OAAOD,SAAS,CAACC,MAAM,CAAC,IAAIF,gBAAgB,GAAG,EAAE;AACnD;AAEA,SAASU,MAAMA,CAACC,KAAe;EAC7B,IAAMC,MAAM,GAAe,EAAE;EAC7B,IAAIC,KAAK,GAAG,CAAC;EAEbF,KAAK,CAACG,OAAO,CAAC,UAACC,IAAI;IACjB,IAAMZ,IAAI,GAAGF,SAAS,CAACW,MAAM,CAACC,KAAK,CAAC,CAAC;IACrC,IAAIV,IAAI,IAAI,EAAE,EAAE;MACdU,KAAK,EAAE;;IAGT,IAAID,MAAM,CAACC,KAAK,CAAC,EAAE;MACjBD,MAAM,CAACC,KAAK,CAAC,CAACG,IAAI,CAACD,IAAI,CAAC;KACzB,MAAM;MACLH,MAAM,CAACC,KAAK,CAAC,GAAG,CAACE,IAAI,CAAC;;EAE1B,CAAC,CAAC;EAEF,OAAOH,MAAM;AACf;AAEA,eAAc,SAAUD,KAAKA,CAC3BM,OAAe,EACfC,MAA+B;;EAE/B,IAAIhB,MAAM,GAAa,EAAE;EACzB,IAAIiB,YAAY,GAAG,KAAK;EAExB,IAAMC,KAAK,GAAG,CAAAC,EAAA,GAAAH,MAAM,aAANA,MAAM,uBAANA,MAAM,CAAEf,IAAI,cAAAkB,EAAA,cAAAA,EAAA,GAAI,EAAE;EAChC,IAAMC,OAAO,GAAG,CAAAC,EAAA,GAAAL,MAAM,aAANA,MAAM,uBAANA,MAAM,CAAEI,OAAO,cAAAC,EAAA,cAAAA,EAAA,GAAI,IAAI;EAEvC,SAASC,SAASA,CAACb,KAAe;;IAChC,IAAIA,KAAK,CAACH,MAAM,KAAK,CAAC,EAAE;MACtB;;IAGF,IAAMiB,QAAQ,GAAG,CAAAJ,EAAA,GAACV,KAAK,CAAC,CAAC,CAAkB,cAAAU,EAAA,uBAAAA,EAAA,CAAEI,QAAQ;IAErD;IACA,IAAMC,YAAY,GAAGf,KAAK,CAACgB,GAAG,CAAC,UAACC,KAAK;MACnC,IAAMP,EAAA,GAA0BO,KAAqB;QAA7CC,MAAM,GAAAR,EAAA,CAAAQ,MAAA;QAAKC,QAAQ,GAAAC,MAAA,CAAAV,EAAA,EAArB,UAAuB,CAAwB;MACrD,OAAOS,QAAQ;IACjB,CAAC,CAAC;IAEF,OAAOhC,KAAK,CAAC,WAAAkC,MAAA,CAAWf,OAAO,OAAI,EAAE;MACnCgB,SAAS,EAAEd,YAAY;MACvBe,OAAO,EAAE;QACP,cAAc,EAAE;OACjB;MACDC,MAAM,EAAE,MAAM;MACdC,IAAI,EAAE/B,IAAI,CAACC,SAAS,CAAC;QACnBmB,QAAQ,EAAAA,QAAA;QACRd,KAAK,EAAEe,YAAY;QACnBG,MAAM,EAAE,IAAIQ,IAAI,EAAE,CAACC,WAAW;OAC/B;KACF,CAAC;EACJ;EAEA,SAAeC,KAAKA,CAAA;;;;QAClB,IAAIrC,MAAM,CAACM,MAAM,EAAE;UACXgC,OAAA,GAAQtC,MAAM;UACpBA,MAAM,GAAG,EAAE;UACX,sBAAOsB,SAAS,CAACgB,OAAK,CAAC;;;;;;EAI3B,IAAIC,QAAoC;EAExC,SAASC,aAAaA,CAAA;IACpB,IAAID,QAAQ,EAAE;MACZ;;IAGFA,QAAQ,GAAGE,UAAU,CAAC;MACpBF,QAAQ,GAAGG,SAAS;MACpBL,KAAK,EAAE,CAACM,KAAK,CAACC,OAAO,CAACC,KAAK,CAAC;IAC9B,CAAC,EAAEzB,OAAO,CAAC;EACb;EAEAvB,YAAY,CAAC,UAACiD,QAAQ;IACpB7B,YAAY,GAAG6B,QAAQ;IAEvB,IAAI7B,YAAY,IAAIjB,MAAM,CAACM,MAAM,EAAE;MACjC,IAAMyC,IAAI,GAAGvC,MAAM,CAACR,MAAM,CAAC,CAACyB,GAAG,CAACH,SAAS,CAAC;MAC1C0B,OAAO,CAACC,GAAG,CAACF,IAAI,CAAC,CAACJ,KAAK,CAACC,OAAO,CAACC,KAAK,CAAC;;EAE1C,CAAC,CAAC;EAEF,SAAeK,QAAQA,CAACC,IAAY,EAAEjB,IAAY;;;;QAChDlC,MAAM,CAACc,IAAI,CAACoB,IAAI,CAAC;QAEXkB,cAAc,GAClBpD,MAAM,CAACM,MAAM,IAAIY,KAAK,IAAIX,2BAA2B,CAACP,MAAM,CAAC;QAE/D,sBAAOoD,cAAc,IAAInC,YAAY,GAAGoB,KAAK,EAAE,GAAGG,aAAa,EAAE;;;;EAGnE,OAAO;IACLU,QAAQ,EAAAA;GACT;AACH","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}